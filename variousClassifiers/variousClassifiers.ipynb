{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2 - 1. 손글씨 분류하기\n",
    "## 1) 데이터 준비\n",
    "load_digits 메서드를 사용하여 데이터를 준비합니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손글씨 데이터 준비하기\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 이해하기\n",
    "다루어야 할 손글씨 데이터를 자세히 살펴보도록 하겠습니다.  \n",
    "데이터를 보기 좋게 하기 위해서 판다스로 데이터 프레임을 생성하여 출력했습니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data 개수 :  1797 개\n",
      "\n",
      "feature (총 64 개) : pixel_0_0, pixel_0_1, pixel_0_2, pixel_0_3, pixel_0_4, pixel_0_5, pixel_0_6, pixel_0_7, pixel_1_0, pixel_1_1, pixel_1_2, pixel_1_3, pixel_1_4, pixel_1_5, pixel_1_6, pixel_1_7, pixel_2_0, pixel_2_1, pixel_2_2, pixel_2_3, pixel_2_4, pixel_2_5, pixel_2_6, pixel_2_7, pixel_3_0, pixel_3_1, pixel_3_2, pixel_3_3, pixel_3_4, pixel_3_5, pixel_3_6, pixel_3_7, pixel_4_0, pixel_4_1, pixel_4_2, pixel_4_3, pixel_4_4, pixel_4_5, pixel_4_6, pixel_4_7, pixel_5_0, pixel_5_1, pixel_5_2, pixel_5_3, pixel_5_4, pixel_5_5, pixel_5_6, pixel_5_7, pixel_6_0, pixel_6_1, pixel_6_2, pixel_6_3, pixel_6_4, pixel_6_5, pixel_6_6, pixel_6_7, pixel_7_0, pixel_7_1, pixel_7_2, pixel_7_3, pixel_7_4, pixel_7_5, pixel_7_6, pixel_7_7\n",
      "\n",
      "label (총 10 개) : 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0           0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1           0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2           0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3           0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4           0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        0.0        4.0       10.0       13.0        6.0   \n",
       "1793        0.0        0.0        6.0       16.0       13.0       11.0   \n",
       "1794        0.0        0.0        1.0       11.0       15.0        1.0   \n",
       "1795        0.0        0.0        2.0       10.0        7.0        0.0   \n",
       "1796        0.0        0.0       10.0       14.0        8.0        1.0   \n",
       "\n",
       "      pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_7  pixel_7_0  \\\n",
       "0           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "3           0.0        0.0        0.0        8.0  ...        0.0        0.0   \n",
       "4           0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1792        0.0        0.0        0.0        1.0  ...        0.0        0.0   \n",
       "1793        1.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1794        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1795        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1796        0.0        0.0        0.0        2.0  ...        0.0        0.0   \n",
       "\n",
       "      pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  pixel_7_6  \\\n",
       "0           0.0        6.0       13.0       10.0        0.0        0.0   \n",
       "1           0.0        0.0       11.0       16.0       10.0        0.0   \n",
       "2           0.0        0.0        3.0       11.0       16.0        9.0   \n",
       "3           0.0        7.0       13.0       13.0        9.0        0.0   \n",
       "4           0.0        0.0        2.0       16.0        4.0        0.0   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1792        0.0        2.0       14.0       15.0        9.0        0.0   \n",
       "1793        0.0        6.0       16.0       14.0        6.0        0.0   \n",
       "1794        0.0        2.0        9.0       13.0        6.0        0.0   \n",
       "1795        0.0        5.0       12.0       16.0       12.0        0.0   \n",
       "1796        1.0        8.0       12.0       14.0       12.0        1.0   \n",
       "\n",
       "      pixel_7_7  label  \n",
       "0           0.0      0  \n",
       "1           0.0      1  \n",
       "2           0.0      2  \n",
       "3           0.0      3  \n",
       "4           0.0      4  \n",
       "...         ...    ...  \n",
       "1792        0.0      9  \n",
       "1793        0.0      0  \n",
       "1794        0.0      8  \n",
       "1795        0.0      9  \n",
       "1796        0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 이해하기\n",
    "import pandas as pd\n",
    "\n",
    "digits_data = digits.data    # 손글씨 데이터\n",
    "digits_label = digits.target    # 손글씨 라벨 데이터\n",
    "digits_label_names = digits.target_names    # 손글씨 라벨의 종류\n",
    "digits_feature = digits.feature_names    # 손글씨 특징의 이름\n",
    "\n",
    "digits_df = pd.DataFrame(data = digits_data, columns = digits_feature)   # 데이터 프레임 생성\n",
    "digits_df[\"label\"] = digits_label    #  손글씨 라벨 데이터 추가\n",
    "\n",
    "print(\"\\ndata 개수 : \", len(digits_data), \"개\")\n",
    "print(\"\\nfeature\", \"(총\", len(digits_feature), \"개) :\", ', '.join(digits_feature))\n",
    "print(\"\\nlabel\", \"(총\", len(digits_label_names),\"개) :\", ', '.join(list(map(str, digits_label_names))))\n",
    "\n",
    "digits_df   # 손글씨 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터는 총 1797개입니다.\n",
    "#### 데이터의 feature는 이미지의 픽셀(8x8)이며, 총 64개입니다.\n",
    "#### 그리고 정답 클래스는 0부터 9까지의 숫자이며, 총 10개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) train, test 데이터 분리하기\n",
    "train_test_split() 함수를 사용하여, 1797개의 손글씨 데이터를 train 데이터와 test데이터로 분리하겠습니다.  \n",
    "train 데이터셋과 test 데이터셋의 비율은 8:2로 하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 개수 : 1437\n",
      "y_train의 개수 : 1437\n",
      "\n",
      "X_test의 개수 : 360\n",
      "y_test의 개수 : 360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터를 8:2 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 7)\n",
    "\n",
    "\n",
    "print(\"X_train의 개수 :\", X_train.shape[0])\n",
    "print(\"y_train의 개수 :\", y_train.shape[0])\n",
    "print()\n",
    "\n",
    "print(\"X_test의 개수 :\", X_test.shape[0])\n",
    "print(\"y_test의 개수 :\", y_test.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8:2 비율로 데이터를 나눈 결과, **train 데이터셋은 1473 개**, **test 데이터셋은 360 개** 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 다양한 모델로 학습시켜보기\n",
    "학습데이터 X_train, y_train 을 활용하여 다양한 분류기 모델을 만들어 보았습니다.  \n",
    "### (1) Decision Tree - 의사 결정 나무\n",
    "**Decision Tree** 는 일련의 분류 기준을 설정한 뒤, 데이터를 분류하거나 예측하여 일련의 규칙을 찾는 알고리즘입니다.  \n",
    "마치 스무고개 하듯이 질문을 이어가며 학습합니다.  \n",
    "분류와 회귀 모두 가능합니다. 즉, 범주나 연속형 수치 모두를 예측할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state = 32)    # 모델 생성\n",
    "decision_tree.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random Forest - 랜덤 포레스트\n",
    "Decision Tree 는 좋은 모델이지만, 학습 데이터에 오버피팅 하는 경향이 있어 일반화가 어렵습니다.  \n",
    "그래서 새로 들어온 데이터에 대해서 성능이 떨어져는 경우가 있습니다.  \n",
    "이러한 오버피팅을 해결하기 위한 알고리즘이 바로, **Random Forest** 입니다.  \n",
    "**Random Forest** 는 Decision Tree 를 여러개 모아 놓은 알고리즘입니다.  \n",
    "즉, **Random Forest** 는 여러 개의 Decision Tree 를 만들고, 투표를 시켜 다수결로 결정하는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state = 32)    # 모델 생성\n",
    "random_forest.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)  SVM(Support Vector Machine) - 서포트 벡터 머신\n",
    "**SVM** 은 결정 경계, 즉 분류를 위한 기준 선을 정의하는 모델입니다.  \n",
    "그래서 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류 과제를 수행할 수 있게 됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM 모델 학습\n",
    "svm_model = svm.SVC()    # 모델 생성\n",
    "svm_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) SGD(Stochastic Gradient Descent) - 확률적 경사 하강법\n",
    "**SGD** 는 추출된 데이터 한개에 대해서 그래디언트를 계산하고 경사 하강 알고리즘을 적용하는 방법을 말합니다.  \n",
    "학습을 할때, 전체 학습 데이터를 사용하는 것이 아니라, 랜덤하게 추출한 일부 데이터를 사용합니다.  \n",
    "  \n",
    "*경사 하강이란 함수의 기울기(경사)를 구하여 기울기가 낮을쪽으로 계속 이동시켜 극값에 이를 때까지 반복하는 것입니다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()    # 모델 생성\n",
    "sgd_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Logistic Regression - 로지스틱 회귀\n",
    "**Logistic Regression** 란 회귀를 사용하여 데이터가 특정 카테고리 속할지 0과 1사이의 연속적인 확률로 예측하고,  \n",
    "그 확률에 따라 가능성이 더 높은 카테고리에 속하는 것으로 분류해주는 알고리즘 입니다.  \n",
    "\n",
    "*회귀의 사전적 의미는 '한 바퀴 돌아서 원래의 자리나 상태로 돌아오는 것'입니다. 데이터의 실측치와 모델의 실측치 사이의 차이가 평균으로 회귀하는 것입니다.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(solver='liblinear')    # 모델 생성\n",
    "logistic_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 각 모델 평가하기\n",
    "각 모델들 (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression) 을 평가하고,   \n",
    "각 모델들의 성능을 평가하는 지표인 accuracy과 f1 score 중 적절한 것이 무엇인지 파악해 보도록 하겠습니다.  \n",
    "또한 데이터의 특성에 따라 precision과 recall의 중요도가 서로 다른데, 그것 또한 파악해 보도록 하겠습니다.\n",
    "\n",
    "### (1) Accuracy(정확도) vs F1 Score\n",
    "- **Accuracy(정확도)**  \n",
    "    **Accuracy** 란 전체 데이터 개수 대비 예측한 데이터 개수의 비율입니다. accuracy는 높을수록 좋은 모형입니다.  \n",
    "    accuracy는 데이터의 클래스가 골고루 퍼져있는 **균형적인 데이터**일때, 모델의 평가지표로 사용합니다.\n",
    "<br/><br/>  \n",
    "- **F1 Score**  \n",
    "    **F1 Score** 는 precision과 recall의 조화평균입니다. f1 score는 높을수록 좋은 모형입니다.  \n",
    "    f1 score는 **불균형 데이터**일때, 모델의 평가지표로 사용합니다.  \n",
    "    \n",
    "### (2) Precision(정밀도) vs Recall(재현율)\n",
    "precision 과 recall 은 데이터의 클래스가 골고루 퍼져있는지 확인할 수 있는 지표입니다. (정답 분포가 balance한지 unbalance한지)  \n",
    "이 두개의 값이 높을수록 균형적인 데이터입니다.\n",
    "- **Precision(정밀도)**  \n",
    "    **Precision** 은 모델이 True라고 분류한 것 중에서 실제 True인 것의 비율입니다. precision은 높을수록 좋습니다.\n",
    "<br/><br/>  \n",
    "- **Recall(재현율)**  \n",
    "    **Recall** 은 실제 True인 것 중에서 모델이 Ture라고 예측한 것의 비율입니다. recall은 높을수록 좋습니다.\n",
    "<br/><br/>\n",
    "- **Precision** 이 크려면 거짓인데 참으로 판단하는 경우가 적어야 합니다. (답을 못찾는건 괜찮은데 잘못 선택하는 경우, precision이 중요)\n",
    "- **Recall** 이 크려면 참인데 거짓으로 판단하는 경우가 적어야 합니다. (답을 잘못 선택하는건 괜찮은데 못찾는 경우, recall이 중요)\n",
    "<br/><br/>\n",
    "- **(예시1)** 전체 메일함에서 스팸 메일을 거르는 모델에게는 precision이 더 중요할까요, recall이 더중요할까요?  \n",
    "    precision : 정상메일인데 스팸메일로 판단하는 경우  \n",
    "    recall : 스팸메일인데 정상메일로 판단하는 경우  \n",
    "    정상메일인데 스팸메일로 분류하는 것이 더 큰 문제이기 때문에 precision이 중요합니다.\n",
    "<br/><br/>\n",
    "- **(예시2)** 암 환자를 진단하는 모델에게는 precision이 더 중요할까요, recall이 더중요할까요?  \n",
    "    precision : 암환자가 아닌데 암으로 판단하는 경우  \n",
    "    recall : 암환자인데 암환자가 아닌것으로 판단하는 경우  \n",
    "    암환자인데 암환자가 아닌것으로 판단하는 것이 더 큰 문제이기 때문에 recall이 중요합니다.  \n",
    "\n",
    "### (3) 모델 성능 평가 지표 확인하기\n",
    "classification_report() 함수를 사용하여 각 모델들의 precision, recall, f1 score 를 확인해 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① Decision Tree - 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Decision Tree 성능 평가\n",
      "\n",
      "정확도 : 0.8555555555555555 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# 모델 평가하기\n",
    "\n",
    "# Decision Tree 모델 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(\"* Decision Tree 성능 평가\\n\")\n",
    "print(\"정확도 :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Decision Tree 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **86%** 입니다. 성능이 꽤 괜찮은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Random Forest - 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Random Forest 성능 평가\n",
      "\n",
      "Accuracy : 0.9638888888888889 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 모델 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(\"\\n* Random Forest 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Random Forest 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **96%** 입니다. 성능이 매우 좋은 모델인 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ SVM(Support Vector Machine) - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SVM 성능 평가\n",
      "\n",
      "Accuracy : 0.9888888888888889 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM 모델 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SVM 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SVM 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **99%** 입니다. 성능이 매우 좋은 모델인 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④ SGD(Stochastic Gradient Descent) - 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SGD Classifier 성능 평가\n",
      "\n",
      "Accuracy : 0.9138888888888889 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.86      0.90      0.88        42\n",
      "           2       0.97      0.97      0.97        40\n",
      "           3       0.91      0.91      0.91        34\n",
      "           4       0.97      0.92      0.94        37\n",
      "           5       0.82      1.00      0.90        28\n",
      "           6       0.93      0.93      0.93        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.97      0.67      0.79        43\n",
      "           9       0.76      0.91      0.83        32\n",
      "\n",
      "    accuracy                           0.91       360\n",
      "   macro avg       0.91      0.92      0.91       360\n",
      "weighted avg       0.92      0.91      0.91       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier 모델 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SGD Classifier 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SGD 모델의 정답의 분포는 어느정도 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **91%** 입니다. 성능이 좋은 모델인 것을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤ Logistic Regression - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Logistic Regression 성능 평가\n",
      "\n",
      "Accuracy : 0.9444444444444444 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.90      0.90      0.90        42\n",
      "           2       0.97      0.97      0.97        40\n",
      "           3       0.86      0.94      0.90        34\n",
      "           4       0.95      0.97      0.96        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.93      0.88      0.90        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.95      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 모델 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* Logistic Regression 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Logistic Regression 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **94%** 입니다. 성능이 좋은 모델인 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 출력된 성능 평가 지표를 정리하면 아래 표와 같습니다. \n",
    "\n",
    "| Model | Accuracy | Precision | Recall | F1 Score |\n",
    "|:----------|:----------:|:----------:|:----------:|:----------:|\n",
    "| **Decision Tree** | 0.86 | 0.86 | 0.86 | 0.86 |\n",
    "| **Random Forest** | 0.96 | 0.96 | 0.96 | 0.96 |\n",
    "| **SVM** | 0.99 | 0.99 | 0.99 | 0.99 |\n",
    "| **SGD Classifier** | 0.91 | 0.91 | 0.92 | 0.91 |\n",
    "| **Logistic Regression** | 0.94 | 0.95 | 0.95 | 0.94 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종합적으로 모든 모델의 성능 평가 지표를 확인한 결과,  \n",
    "**손글씨를 분류** 하는 문제는 모든 모델에 대해 **accuracy**로 모델의 성능을 평가했습니다.  \n",
    "\n",
    "[ **accuracy 로 판별한 모델 순위** ]\n",
    "1. SVM (99%)\n",
    "2. Random Forest (96%)\n",
    "3. Logistic Regression (94%)\n",
    "4. SGD Classifier (91%)\n",
    "5. Desicion Tree (86%)  \n",
    "  \n",
    "**손글씨를 분류** 하는 문제는 **SVM 모델** 에 가장 적합한 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# PROJECT 2 - 2. 와인 분류하기\n",
    "## 1) 데이터 준비\n",
    "load_wine 메서드를 사용하여 데이터를 준비합니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 와인 데이터 준비하기\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wines = load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 이해하기\n",
    "다루어야 할 와인 데이터를 자세히 살펴보도록 하겠습니다.  \n",
    "데이터를 보기 좋게 하기 위해서 판다스로 데이터 프레임을 생성하여 출력했습니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data 개수 :  178 개\n",
      "\n",
      "feature (총 13 개) : alcohol, malic_acid, ash, alcalinity_of_ash, magnesium, total_phenols, flavanoids, nonflavanoid_phenols, proanthocyanins, color_intensity, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "label (총 3 개) : class_0, class_1, class_2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  label  \n",
       "0                            3.92   1065.0      0  \n",
       "1                            3.40   1050.0      0  \n",
       "2                            3.17   1185.0      0  \n",
       "3                            3.45   1480.0      0  \n",
       "4                            2.93    735.0      0  \n",
       "..                            ...      ...    ...  \n",
       "173                          1.74    740.0      2  \n",
       "174                          1.56    750.0      2  \n",
       "175                          1.56    835.0      2  \n",
       "176                          1.62    840.0      2  \n",
       "177                          1.60    560.0      2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 이해하기\n",
    "import pandas as pd\n",
    "\n",
    "wines_data = wines.data    # 와인 데이터\n",
    "wines_label = wines.target    # 와인 라벨 데이터\n",
    "wines_label_names = wines.target_names    # 와인 라벨의 종류\n",
    "wines_feature = wines.feature_names    # 와인 특징의 이름\n",
    "\n",
    "wines_df = pd.DataFrame(data = wines_data, columns = wines_feature)   # 데이터 프레임 생성\n",
    "wines_df[\"label\"] = wines_label    #  와인 라벨 데이터 추가\n",
    "\n",
    "print(\"\\ndata 개수 : \", len(wines_data), \"개\")\n",
    "print(\"\\nfeature\", \"(총\", len(wines_feature), \"개) :\", ', '.join(wines_feature))\n",
    "print(\"\\nlabel\", \"(총\", len(wines_label_names),\"개) :\", ', '.join(list(map(str, wines_label_names))))\n",
    "\n",
    "wines_df   # 와인 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터는 총 178개입니다.\n",
    "#### 데이터의 feature는 와인 안에 들어있는 성분 (alcohol, ash, flavanoids, ...) 이며, 총 13개입니다.\n",
    "#### 그리고 정답 클래스는 와인 종류(class_0, class_1, class_2)이며, 총 3개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) train, test 데이터 분리하기\n",
    "train_test_split() 함수를 사용하여, 178개의 와인 데이터를 train 데이터와 test데이터로 분리하겠습니다.  \n",
    "train 데이터셋과 test 데이터셋의 비율은 8:2로 하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 개수 : 142\n",
      "y_train의 개수 : 142\n",
      "\n",
      "X_test의 개수 : 36\n",
      "y_test의 개수 : 36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터를 8:2 비율로 나누기\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, wines_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 7)\n",
    "\n",
    "\n",
    "print(\"X_train의 개수 :\", X_train.shape[0])\n",
    "print(\"y_train의 개수 :\", y_train.shape[0])\n",
    "print()\n",
    "\n",
    "print(\"X_test의 개수 :\", X_test.shape[0])\n",
    "print(\"y_test의 개수 :\", y_test.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8:2 비율로 데이터를 나눈 결과, **train 데이터셋은 142 개**, **test 데이터셋은 36 개** 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 다양한 모델로 학습시켜보기\n",
    "학습데이터 X_train, y_train 을 활용하여 다양한 분류기 모델을 만들어 보았습니다.  \n",
    "### (1) Decision Tree - 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=7)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state = 7)    # 모델 생성\n",
    "decision_tree.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random Forest - 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=7)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state = 7)    # 모델 생성\n",
    "random_forest.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)  SVM(Support Vector Machine) - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM 모델 학습\n",
    "svm_model = svm.SVC()    # 모델 생성\n",
    "svm_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) SGD(Stochastic Gradient Descent) - 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()    # 모델 생성\n",
    "sgd_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Logistic Regression - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(solver='liblinear')    # 모델 생성\n",
    "logistic_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 각 모델 평가하기\n",
    "각 모델들 (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression) 을 평가하고,   \n",
    "각 모델들의 성능을 평가하는 지표인 accuracy과 f1 score 중 적절한 것이 무엇인지 파악해 보도록 하겠습니다.  \n",
    "또한 데이터의 특성에 따라 precision과 recall의 중요도가 서로 다른데, 그것 또한 파악해 보도록 하겠습니다.\n",
    " \n",
    "### (1) 모델 성능 평가 지표 확인하기\n",
    "classification_report() 함수를 사용하여 각 모델들의 precision, recall, f1 score 를 확인해 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① Decision Tree - 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Decision Tree 성능 평가\n",
      "\n",
      "정확도 : 0.9166666666666666 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.92      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# 모델 평가하기\n",
    "\n",
    "# Decision Tree 모델 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(\"* Decision Tree 성능 평가\\n\")\n",
    "print(\"정확도 :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Decision Tree 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **92%** 의 정확도를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Random Forest - 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Random Forest 성능 평가\n",
      "\n",
      "Accuracy : 1.0 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 모델 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(\"\\n* Random Forest 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Random Forest 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **100%** 의 정확도를 가진 성능이 매우 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ SVM(Support Vector Machine) - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SVM 성능 평가\n",
      "\n",
      "Accuracy : 0.6111111111111112 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM 모델 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SVM 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SVM 모델의 정답의 분포는 **unbalance** 합니다. 특히, class_2를 잘 분류해내지 못합니다.  \n",
    "아마도 class_2에 대한 데이터를 더 넣어주면 모델의 성능이 나아질 것 입니다.  \n",
    "unbalance한 데이터이기 때문에 accuracy 가 아니라 **f1 score** 로 모델의 성능을 평가하면 됩니다.  \n",
    "f1 score를 확인해보니, **56%** 의 f1 스코어를 가진 성능이 안좋은 모델인 것을 확인할 수 있습니다.  \n",
    "(accuracy로 확인하면 61% 인데, 사실 61% 보다 성능이 더 안좋은 것이죠.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④ SGD(Stochastic Gradient Descent) - 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SGD Classifier 성능 평가\n",
      "\n",
      "Accuracy : 0.6388888888888888 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82         7\n",
      "           1       0.62      0.94      0.74        17\n",
      "           2       0.00      0.00      0.00        12\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.44      0.65      0.52        36\n",
      "weighted avg       0.43      0.64      0.51        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier 모델 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SGD Classifier 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SGD 모델의 정답의 분포는 **unbalance** 합니다.  \n",
    "특히 정답이 class_2인 데이터를 1개도 분류해내지 못합니다. 정말 좋지 않은 상황입니다.  \n",
    "아마도 class_2에 대한 데이터를 더 넣어주면 모델의 성능이 나아질 것 입니다.   \n",
    "unbalance한 데이터이기 때문에 accuracy 가 아니라 **f1 score** 로 모델의 성능을 평가하면 됩니다.  \n",
    "f1 score를 확인해보니, **52%** 의 f1 스코어를 가진 성능이 아주 안좋은 모델인 것을 확인할 수 있습니다.  \n",
    "(accuracy로 확인하면 64% 인데, 사실 64% 보다 성능이 더 안좋은 것이죠.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤ Logistic Regression - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Logistic Regression 성능 평가\n",
      "\n",
      "Accuracy : 0.9722222222222222 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.94      0.97        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.96      0.98      0.97        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 모델 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* Logistic Regression 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Logistic Regression 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **97%** 의 정확도를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 출력된 성능 평가 지표를 정리하면 아래 표와 같다.  \n",
    "\n",
    "| Model | Accuracy | Precision | Recall | F1 Score |\n",
    "|:----------|:----------:|:----------:|:----------:|:----------:|\n",
    "| **Decision Tree** | 0.92 | 0.92 | 0.92 | 0.92 |\n",
    "| **Random Forest** | 1.0 | 1.0 | 1.0 | 1.0 |\n",
    "| **SVM** | 0.61 | 0.59 | 0.61 | 0.56 |\n",
    "| **SGD Classifier** | 0.64 | 0.44 | 0.65 | 0.52 |\n",
    "| **Logistic Regression** | 0.97 | 0.96 | 0.98 | 0.97 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종합적으로 모든 모델의 성능 평가 지표를 확인한 결과,  \n",
    "**와인을 분류** 하는 문제는 **SVM 과 SGD Classifier는 f1 socre** 로, 그 **이외의 모델은 accuracy** 로 모델의 성능을 평가했습니다.  \n",
    "\n",
    "[ **accuracy 와 f1 score 로 판별한 모델 순위** ]\n",
    "1. Random Forest (100%)\n",
    "2. Logistic Regression (97%)\n",
    "3. Desicion Tree (92%)\n",
    "4. SVM (56%)\n",
    "5. SGD Classifier (52%)\n",
    "\n",
    "  \n",
    "**와인을 분류** 하는 문제는 **Random Forest 모델** 에 가장 적합한 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "# PROJECT 2 - 3. 유방암 여부 진단하기\n",
    "## 1) 데이터 준비\n",
    "load_breast_cancer 메서드를 사용하여 데이터를 준비합니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유방암 데이터 준비하기\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "breast_cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 이해하기\n",
    "다루어야 할 유방암 데이터를 자세히 살펴보도록 하겠습니다.  \n",
    "데이터를 보기 좋게 하기 위해서 판다스로 데이터 프레임을 생성하여 출력했습니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data 개수 :  569 개\n",
      "\n",
      "feature (총 30 개) : mean radius, mean texture, mean perimeter, mean area, mean smoothness, mean compactness, mean concavity, mean concave points, mean symmetry, mean fractal dimension, radius error, texture error, perimeter error, area error, smoothness error, compactness error, concavity error, concave points error, symmetry error, fractal dimension error, worst radius, worst texture, worst perimeter, worst area, worst smoothness, worst compactness, worst concavity, worst concave points, worst symmetry, worst fractal dimension\n",
      "\n",
      "label (총 2 개) : malignant, benign\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 이해하기\n",
    "import pandas as pd\n",
    "\n",
    "breast_cancer_data = breast_cancer.data    # 유방암 데이터\n",
    "breast_cancer_label = breast_cancer.target    # 유방암 라벨 데이터\n",
    "breast_cancer_label_names = breast_cancer.target_names    # 유방암 라벨의 종류\n",
    "breast_cancer_feature = breast_cancer.feature_names    # 유방암 특징의 이름\n",
    "\n",
    "breast_cancer_df = pd.DataFrame(data = breast_cancer_data, columns = breast_cancer_feature)   # 데이터 프레임 생성\n",
    "breast_cancer_df[\"label\"] = breast_cancer_label    # 유방암 라벨 데이터 추가\n",
    "\n",
    "print(\"\\ndata 개수 : \", len(breast_cancer_data), \"개\")\n",
    "print(\"\\nfeature\", \"(총\", len(breast_cancer_feature), \"개) :\", ', '.join(breast_cancer_feature))\n",
    "print(\"\\nlabel\", \"(총\", len(breast_cancer_label_names),\"개) :\", ', '.join(list(map(str, breast_cancer_label_names))))\n",
    "\n",
    "breast_cancer_df   # 유방암 데이터 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터는 총 569개입니다.\n",
    "#### 데이터의 평균 반경, 평균 둘레, 평균 면적 등 유방암에 관한 정보이며, 총 30개입니다.\n",
    "#### 그리고 정답 클래스는 음성과 양성이며, 총 2개입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) train, test 데이터 분리하기\n",
    "train_test_split() 함수를 사용하여, 569개의 와인 데이터를 train 데이터와 test데이터로 분리하겠습니다.  \n",
    "train 데이터셋과 test 데이터셋의 비율은 8:2로 하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train의 개수 : 455\n",
      "y_train의 개수 : 455\n",
      "\n",
      "X_test의 개수 : 114\n",
      "y_test의 개수 : 114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data, breast_cancer_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 7)\n",
    "\n",
    "\n",
    "print(\"X_train의 개수 :\", X_train.shape[0])\n",
    "print(\"y_train의 개수 :\", y_train.shape[0])\n",
    "print()\n",
    "\n",
    "print(\"X_test의 개수 :\", X_test.shape[0])\n",
    "print(\"y_test의 개수 :\", y_test.shape[0])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8:2 비율로 데이터를 나눈 결과, **train 데이터셋은 455 개**, **test 데이터셋은 114 개** 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 다양한 모델로 학습시켜보기\n",
    "학습데이터 X_train, y_train 을 활용하여 다양한 분류기 모델을 만들어 보았습니다.  \n",
    "### (1) Decision Tree - 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree 모델 학습\n",
    "decision_tree = DecisionTreeClassifier(random_state = 32)    # 모델 생성\n",
    "decision_tree.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Random Forest - 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest 모델 학습\n",
    "random_forest = RandomForestClassifier(random_state = 32)    # 모델 생성\n",
    "random_forest.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)  SVM(Support Vector Machine) - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM 모델 학습\n",
    "svm_model = svm.SVC()    # 모델 생성\n",
    "svm_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) SGD(Stochastic Gradient Descent) - 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGD Classifier 모델 학습\n",
    "sgd_model = SGDClassifier()    # 모델 학습\n",
    "sgd_model.fit(X_train, y_train)    # 모델 생성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Logistic Regression - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression 모델 학습\n",
    "logistic_model = LogisticRegression(solver='liblinear')    # 모델 생성\n",
    "logistic_model.fit(X_train, y_train)    # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 각 모델 평가하기\n",
    "각 모델들 (Decision Tree, Random Forest, SVM, SGD Classifier, Logistic Regression) 을 평가하고,   \n",
    "각 모델들의 성능을 평가하는 지표인 accuracy과 f1 score 중 적절한 것이 무엇인지 파악해 보도록 하겠습니다.  \n",
    "또한 데이터의 특성에 따라 precision과 recall의 중요도가 서로 다른데, 그것 또한 파악해 보도록 하겠습니다.\n",
    " \n",
    "### (1) 모델 성능 평가 지표 확인하기\n",
    "classification_report() 함수를 사용하여 각 모델들의 precision, recall, f1 score 를 확인해 보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① Decision Tree - 의사 결정 나무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Decision Tree 성능 평가\n",
      "\n",
      "정확도 : 0.9122807017543859 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# 모델 평가하기\n",
    "\n",
    "# Decision Tree 모델 예측\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "print(\"* Decision Tree 성능 평가\\n\")\n",
    "print(\"정확도 :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Decision Tree 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **91%** 의 정확도를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② Random Forest - 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Random Forest 성능 평가\n",
      "\n",
      "Accuracy : 1.0 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 모델 예측\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(\"\\n* Random Forest 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Random Forest 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **100%** 의 정확도를 가진 성능이 매우 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ SVM(Support Vector Machine) - 서포트 벡터 머신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SVM 성능 평가\n",
      "\n",
      "Accuracy : 0.9035087719298246 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM 모델 예측\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SVM 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SVM 모델의 정답의 분포는 어느정도 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **90%** 의 accuracy를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④ SGD(Stochastic Gradient Descent) - 확률적 경사 하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* SGD Classifier 성능 평가\n",
      "\n",
      "Accuracy : 0.9122807017543859 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier 모델 예측\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* SGD Classifier 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, SGD 모델의 정답의 분포는 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **91%** 의 accuracy를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤ Logistic Regression - 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Logistic Regression 성능 평가\n",
      "\n",
      "Accuracy : 0.9473684210526315 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 모델 예측\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(\"\\n* Logistic Regression 성능 평가\\n\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred), \"\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precision 과 recall 을 확인해보니, Logistic Regression 모델의 정답의 분포는 어느정도 **balance** 합니다.  \n",
    "balance한 데이터이기 때문에 f1 score 가 아니라 **accuracy** 로 모델의 성능을 평가하면 됩니다.  \n",
    "accuracy를 확인해보니, **95%** 의 정확도를 가진 성능이 좋은 모델인 것을 확인할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 출력된 성능 평가 지표를 정리하면 아래 표와 같다.  \n",
    "\n",
    "| Model | Accuracy | Precision | Recall | F1 Score |\n",
    "|:----------|:----------:|:----------:|:----------:|:----------:|\n",
    "| **Decision Tree** | 0.91 | 0.91 | 0.89 | 0.90 |\n",
    "| **Random Forest** | 1.0 | 1.0 | 1.0 | 1.0 |\n",
    "| **SVM** | 0.90 | 0.94 | 0.86 | 0.89 |\n",
    "| **SGD Classifier** | 0.91 | 0.91 | 0.89 | 0.90 |\n",
    "| **Logistic Regression** | 0.95 | 0.96 | 0.93 | 0.94 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종합적으로 모든 모델의 성능 평가 지표를 확인한 결과,  \n",
    "**유방암을 분류** 하는 문제는 모든 모델에 대해 **accuracy**로 모델의 성능을 평가했습니다.  \n",
    "\n",
    "[ **accuracy 로 판별한 모델 순위** ]\n",
    "1. Random Forest (100%)\n",
    "2. Logistic Regression (95%)\n",
    "3. SGD Classifier (91%)\n",
    "3. Desicion Tree (91%)\n",
    "5. SVM (90%)  \n",
    "  \n",
    "**유방암을 분류** 하는 문제는 **Random Forest 모델** 에 가장 적합한 것 같습니다.  \n",
    "또한 유방암이 아닌데 유방암으로 판단하는 경우보다 유방암인데 유방암이 아닌것으로 판단하는 경우가 더 중요하기 때문에  \n",
    "presicion 보다 **recall** 이 더 중요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 결과 및 느낀점]\n",
    "손글씨 데이터, 와인 데이터, 유방암 데이터들을 여러가지 머신러닝 모델들(Decision Tree, Random Forest, SVM, SGD, Logistic Regression)에 학습시켜본 후, 모델이 데이터를 잘 학습하였는지 평가해보는 프로젝트를 하였습니다. 저는 항상 모델들의 성능을 평가할 때, accuracy 만 보고 성능을 평가했는데, accuracy만 보고 성능을 판단하면 절대 안된다는 것을 이 프로젝트를 해봄으로써 깨닫게 되었습니다. 즉, 모델의 성능을 평가할때는 accuracy 이외에도 f1 score, precision, recall을 확인해야 한다는 것을 알게 되었습니다. 그리고 precision과 recall 을 확인함으로써 안좋은 성능을 가진 모델을 어떻게 하면 좋게 만들 수 있는지도 알게 되었습니다. 해당 클래스의 recall이나 precision 이 낮으면 그 클래스의 데이터가 부족하다는 의미이기 때문에 precision과 recall 이 낮은 클래스의 데이터를 추가하여 학습시키면 성능을 좋게 만들 수 있습니다.  \n",
    "<br/>\n",
    "이 프로젝트를 하고 내가 깨닫게 된 것을 한줄로 적어보면 아래와 같습니다.  \n",
    "> **\"모델의 성능을 평가할 때, accuracy, f1 socre, precision, recall 을 가지고 평가하자!\"**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
