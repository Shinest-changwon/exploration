{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 1. 가위바위보 분류기 만들기\n",
    "## 1) 데이터 수집\n",
    "머신러닝을 하기 위해서는 기계에 학습시켜야 할 데이터가 필요합니다.  \n",
    "#### (1) teachable machine 사이트에서 가위, 바위, 보 이미지 데이터 만들기\n",
    ": 노트북 전면 카메라를 활용하여 가위, 바위, 보 이미지 각 100장을 만들었습니다. \n",
    "#### (2) 폴더를 생성하여 가위, 바위, 보 이미지 저장\n",
    ": originalData 폴더 아래에 scissor, rock, paper 폴더를 만들어서 이미지를 저장하였습니다.  \n",
    "<br/>\n",
    "## 2) 데이터 전처리\n",
    "수집한 데이터를 머신러닝 알고리즘에 알맞은 데이터로 바꿔야 합니다.  \n",
    "<br/>\n",
    "현재 가위, 바위, 보 이미지의 크기는 224x244 입니다. 머신러닝 알고리즘에 알맞은 데이터로 바꾸기 위해 이미지를 resize 해야합니다.  \n",
    "224x244 크기의 이미지를 28x28 크기의 이미지로 resize 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 가위 이미지 resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/exploration/rock_scissor_paper/originalData/scissor\n",
      "이미지 개수 : 100\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일 읽기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/originalData/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"이미지 개수 :\", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장하기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/trainData/scissor\"\n",
    "target_size = (28,28)\n",
    "number = 0\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(image_dir_path + \"/{}.jpg\".format(number))\n",
    "    number = number + 1\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 바위 이미지 resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/exploration/rock_scissor_paper/originalData/rock\n",
      "이미지 개수 : 100\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일 읽기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/originalData/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"이미지 개수 :\", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장하기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/trainData/rock\"\n",
    "target_size = (28,28)\n",
    "number = 0\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(image_dir_path + \"/{}.jpg\".format(number))\n",
    "    number = number + 1\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3) 보 이미지 resize 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/exploration/rock_scissor_paper/originalData/paper\n",
      "이미지 개수 : 100\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일 읽기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/originalData/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images = glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "print(\"이미지 개수 :\", len(images))\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장하기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/trainData/paper\"\n",
    "target_size = (28,28)\n",
    "number = 0\n",
    "for img in images:\n",
    "    old_img = Image.open(img)\n",
    "    new_img = old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(image_dir_path + \"/{}.jpg\".format(number))\n",
    "    number = number + 1\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 가위, 바위, 보 데이터를 읽을 수 있는 함수 만들기\n",
    "가위, 바위, 보 데이터를 읽을 수 있는 함수 load_data 를 만들고, 실행하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    number_of_data = 300   # 폴더 안에 있는 가위바위보 이미지 개수 총합\n",
    "    img_size = 28   # 이미지 크기\n",
    "    color = 3   # 흑백 이미지 = 0, 칼라 이미지 = 3\n",
    "    \n",
    "    # 이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs = np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels = np.zeros(number_of_data,dtype=np.int32)\n",
    "    \n",
    "    # 확장자 불러오기\n",
    "    temp = glob.glob(img_path + \"/scissor/*.jpeg\")\n",
    "    if len(temp) == 0:\n",
    "        temp = glob.glob(img_path+\"/scissor/*.jpg\")   \n",
    "        if len(temp) == 0:\n",
    "            extension = \"png\"\n",
    "        else:\n",
    "            extension = \"jpg\"\n",
    "    else:\n",
    "        extension = \"jpeg\"\n",
    "\n",
    "    idx = 0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.{}'.format(extension)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 0   # 가위 : 0\n",
    "        idx = idx + 1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.{}'.format(extension)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 1   # 바위 : 1\n",
    "        idx = idx + 1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.{}'.format(extension)):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:] = img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx] = 2   # 보 : 2\n",
    "        idx = idx + 1\n",
    "\n",
    "    print(\"이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/trainData\"\n",
    "(x_train, y_train) = load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델링\n",
    "데이터 준비가 끝났으니, 이제 가위바위보를 인식하는 딥러닝 네트워크를 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               80100     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 85,491\n",
      "Trainable params: 85,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델 학습\n",
    "모델을 설계하였으니, 이제 학습을 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1273 - accuracy: 0.3433\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.1084 - accuracy: 0.3367\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0772 - accuracy: 0.3967\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0483 - accuracy: 0.6933\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.0065 - accuracy: 0.6433\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.9406 - accuracy: 0.7133\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8264 - accuracy: 0.7433\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7633\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7833\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4122 - accuracy: 0.8167\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3849 - accuracy: 0.8233\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3623 - accuracy: 0.8167\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3590 - accuracy: 0.8500\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3240 - accuracy: 0.8400\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.3226 - accuracy: 0.8400\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.8900\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2749 - accuracy: 0.8633\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2883 - accuracy: 0.8733\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.9067\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(x_train_reshaped, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 모델 평가\n",
    "학습시킨 모델이 얼마나 잘 만들었는지 확인하기 위해 평가해보도록 하겠습니다.  \n",
    "팀원에게 가위바위보 사진 300장(새로운 이미지)을 받고, 그 사진을 test 데이터로 사용하여, 정확성을 측정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n",
      "10/10 - 0s - loss: 2.8366 - accuracy: 0.2367\n",
      "test_loss: 2.8365931510925293 \n",
      "test_accuracy: 0.23666666448116302\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만들기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/testData\"\n",
    "(x_test, y_test) = load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "x_test_reshaped = x_test_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "300개의 test 데이터로 모델을 평가한 결과, 정확성은 약 **24%** 가 나왔습니다. 아주 좋지 않은 결과입니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 피드백 ]\n",
    "train accuracy는 **90%** 인데, test accuracy는 **24%** 입니다. 너무 과도하게 오버 피팅이 되었습니다.  \n",
    "만들고자 하는 가위바위보 분류기의 test accuracy는 60% 이상이기 때문에 개선할 방법을 찾아야 합니다.  \n",
    "아마 train 데이터가 너무 적기 때문에 발생한 것 같습니다. **train 데이터를 더 늘려서 모델을 다시 만들어 보도록 하겠습니다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 데이터 늘리기\n",
    "21명의 이미지 데이터(6300장)를 수집하였습니다.  \n",
    "나의 이미지 데이터를 포함하여, 총 데이터 개수를 300장에서 6600장으로 대폭 늘렸습니다.  \n",
    "data_6600 폴더를 만들어서 이미지를 저장하였습니다.\n",
    "load_data 함수를 사용하여 수집한 가위, 바위, 보 사진을 읽어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 100 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 200 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "이미지 개수는 300 입니다.\n",
      "x_data shape: (6600, 28, 28, 3)\n",
      "y_data shape: (6600,)\n"
     ]
    }
   ],
   "source": [
    "# 폴더 내에 있는 모든 이미지 불러오기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/exploration/rock_scissor_paper/data_6600\"\n",
    "dir_list = os.listdir(image_dir_path)\n",
    "\n",
    "first = True\n",
    "for dir in dir_list:\n",
    "    if first == True:\n",
    "        (x_data, y_data) = load_data(image_dir_path + \"/{}\".format(dir))\n",
    "        first = False\n",
    "    else:\n",
    "        (x_data_temp, y_data_temp) = load_data(image_dir_path + \"/{}\".format(dir))\n",
    "        x_data = np.vstack((x_data, x_data_temp))     \n",
    "        y_data = np.hstack((y_data, y_data_temp))\n",
    "\n",
    "print(\"x_data shape: {}\".format(x_data.shape))\n",
    "print(\"y_data shape: {}\".format(y_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 데이터 나누기\n",
    "6600장의 사진을 9:1 비율로 train 데이터와 test 데이터로 나눕니다.  \n",
    "train 데이터 : 5940개  \n",
    "test 데이터 : 660개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5940, 28, 28, 3)\n",
      "(5940,)\n",
      "(660, 28, 28, 3)\n",
      "(660,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.1, shuffle = True, random_state = 42)\n",
    "x_train_norm = x_train / 255.0\n",
    "x_test_norm = x_test / 255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 모델 학습\n",
    "기존에 설계된 모델과 5940개의 train 데이터를 가지고 학습시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 1.0433 - accuracy: 0.5162\n",
      "Epoch 2/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.6913 - accuracy: 0.7047\n",
      "Epoch 3/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8165\n",
      "Epoch 4/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.3499 - accuracy: 0.8699\n",
      "Epoch 5/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.2534 - accuracy: 0.9072\n",
      "Epoch 6/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.9291\n",
      "Epoch 7/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1720 - accuracy: 0.9382\n",
      "Epoch 8/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9611\n",
      "Epoch 9/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9697\n",
      "Epoch 10/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9732\n",
      "Epoch 11/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9801\n",
      "Epoch 12/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9793\n",
      "Epoch 13/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9798\n",
      "Epoch 14/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9872\n",
      "Epoch 15/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0339 - accuracy: 0.9914\n",
      "Epoch 16/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9936\n",
      "Epoch 17/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9971\n",
      "Epoch 19/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0144 - accuracy: 0.9980\n",
      "Epoch 20/20\n",
      "186/186 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# epoch에 따른 훈련 데이터 정확성 그래프\\nplt.plot(results.history['accuracy'])\\n#plt.plot(results.history['val_acc'])\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\nplt.legend(['train'], loc='upper left')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(x_train_reshaped, y_train, epochs=20)\n",
    "\n",
    "'''\n",
    "# epoch에 따른 훈련 데이터 정확성 그래프\n",
    "plt.plot(results.history['accuracy'])\n",
    "#plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 모델 평가\n",
    "새롭게 학습시킨 모델이 얼마나 잘 만들었는지 확인하기 위해 평가해보도록 하겠습니다.  \n",
    "660개의 test 데이터를 사용하여, 모델의 정확성을 측정하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 - 0s - loss: 0.0796 - accuracy: 0.9818\n",
      "test_loss: 0.07961215078830719 \n",
      "test_accuracy: 0.9818181991577148\n"
     ]
    }
   ],
   "source": [
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 3)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ 결과 및 느낀점]\n",
    "660개의 test 데이터로 모델을 평가한 결과, 정확성은 **98%** 가 나왔습니다. 아주 좋은 결과입니다.  \n",
    "train 데이터를 300개에서 5940개로 늘리기만 했을뿐인데, 정확도가 이전보다 훨씬 좋아졌습니다.  \n",
    "저는 이 프로젝트를 하면서 모델을 설계할 때, **train 데이터의 개수가 엄청나게 중요하다**는 것을 깨닫게 되었습니다.  \n",
    "아무리 딥러닝 알고리즘을 잘 설계했다고 하더라도, train 데이터가 적으면 좋은 모델을 만들 수 없다는 것을 알게 되었습니다.  \n",
    "앞으로 딥러닝 모델을 만들 때, 꼭 충분한 데이터를 수집할 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
